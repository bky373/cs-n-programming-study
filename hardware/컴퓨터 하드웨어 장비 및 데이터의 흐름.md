## 컴퓨터 하드웨어 장비 및 데이터의 흐름

## 목차

1. [하드웨어](#1-하드웨어)
2. [서버 내부 구성](#2-서버-내부-구성)
3. [CPU](#3-CPU)
4. [메모리](#4-메모리)
5. [입출력 장치](#5-입출력-장치)
6. [버스](#6-버스)
7. [정리](#7-정리)

## 1. 하드웨어

> Hardware, 실체가 있는 것

**하드웨어**는 `Hard(단단한)`와 `Ware(제품)`의 합성어로, 단단한 제품, 즉 **실체가 있는 제품**을 가리킨다. 

> 이와 대조적인 용어로, **소프트웨어**도 있다. `soft(부드러운)`와 `ware(제품)`의 합성어로, 흔히 컴퓨터 **프로그램**을 소프트웨어로 이야기한다.

특별히 이 장에서 살펴볼 하드웨어는 **물리 서버**를 이루는 하드웨어들로, 크게 **CPU, 메모리, 입출력 장치** 가 있다. 그리고 이들을 각각 살펴보며 하드웨어 내부에서 **데이터가 어떻게 흐르고 있는지** 살펴볼 예정이다. 아래 사진은 흔히 볼 수 있는 서버 장비의 예이다. 

<img src=https://images.velog.io/images/bky373/post/ee9edd3b-7f70-4a0e-979b-bd2877119a97/image.png width=500px height=280px >

> Ref. [대장님 - IT 블로그](https://m.blog.naver.com/PostView.nhn?blogId=jaemincap&logNo=220397856529&proxyReferer=https:%2F%2Fwww.google.com%2F)

## 2. 서버 내부 구성

서버는 사실 엄청나게 특별한 것이 아니다. 아래 그림에서 알 수 있듯, 서버 장비 내부에는 흔히 가정에서 사용하는 **PC 부품과 같은 종류의 부품**이 들어있다(모니터 없는 본체를 생각해보자).

<img src=https://images.velog.io/images/bky373/post/8dce9582-48d8-4fb0-99a6-6e975c6b5419/image.png width=480px height=360px >

> Ref.  [DB의 DB님 블로그 - 물리 서버 내부 구조](https://dabingk.tistory.com/24)

다만, 서버와 데스크톱 PC의 다른 점은 **설계 목적**에 있다. 자세한 내용은 [이곳](https://library.gabia.com/contents/infrahosting/794/)을 참조하자.

아래 다른 사진을 살펴보자.

<img src=https://images.velog.io/images/bky373/post/4c8441bd-72b9-4d8d-b743-5462c643921d/image.png width=540px height=360px >

>  Ref. [DB의 DB님 블로그 - 물리 서버 내부 구조](https://dabingk.tistory.com/24)

한 번 더 강조하자면, 컴퓨터의 하드웨어는 크게 **CPU, 메모리, 입출력 장치** 등으로 구성되어 있다. <br>여기에 한 가지를 추가하자면, 각 장치는 서로 **(시스템) 버스** 로 연결되어 있다. 아래 항목에서부터, 각 구성 요소에 대해 자세히 살펴보자.

## 3. CPU

> Central Processing Unit, 중앙 처리 장치

CPU는 **서버 중심**에 위치하고 있고, (누군가로부터) **명령을 받아** 데이터 **연산 처리**를 수행한다. 1초에 약 10억 회 이상의 연산을 수행하며, 모든 하드웨어 장치의 동작을 제어한다. 연산시 사용하는 명령/데이터는 기억장치나 입출력 장치를 통해 전달된다.

> 참고로, CPU는 명령을 **받아** 연산을 실행한다고 했다. <br>그렇다면 CPU에게 명령을 내리는 주체는 누구일까?<br>명령을 **내리는** 주체는 바로 OS이다. 그리고 더 깊게 들어가<br>OS에게 명령을 내리는 건, 컴퓨터의 각 프로세스 또는 키보드, 마우스를 통한 입력이다.
>
> * 프로세스는 OS 위에서 작동하고 있는 프로그램(게임이나 문서 작성 프로그램 등)을 말한다

**명령 흐름 요약**

> `키보드`,  `마우스`,  `프로세스` ->  `OS`  -> `CPU`

이번에는 그림을 통해 명령 흐름을 살펴보자. 

<img src=https://images.velog.io/images/bky373/post/ecfbad7f-281a-441c-8fa7-3a4f8b0b1fa0/image.png width=480px height=360px >

> Ref.  [DB의 DB님 블로그 - 물리 서버 내부 구조](https://dabingk.tistory.com/24)

이처럼 그림에서 알 수 있듯, CPU는 OS로부터 명령받기를 기다리고 있다.

## 4. 메모리

> (Main) Memory, 주기억장치<br>RAM (칠판) 또는 ROM으로 분류

메모리는 그 이름 그대로 **기억 공간**을 의미한다. CPU에 데이터를 전달하거나 처리 결과를 전달 받거나 하며 CPU 옆에서 **CPU와 데이터를 교환** 한다. 

안타깝게도 **서버를 재시작하면** 메모리에 저장된 **정보는 사라진다**. 따라서 메모리에 저장되는 **정보는 영구히 저장되지 않는다.**   

반면, 데이터 저장시 **전기적인 처리**만을 사용해 데이터를 저장할 수 있다는 특징을 갖고 있다. 따라서 보조 기억 장치에 비해 **데이터 접근 속도가 빠르다**.

전반적인 메모리 계층 구조를 살펴보면 다음과 같다.

<img src=https://images.velog.io/images/bky373/post/a607e1b2-c038-4417-8986-f9e183d27293/image.png width=420px height=300px>

> Ref. [서비님 블로그 - 시스템 메모리 계층 구조](https://constructor.tistory.com/18)

### CPU 메모리

한편, CPU 내부에서도 메모리를 찾아볼 수 있다. 내부적으로 CPU는 다음의  메모리들을 가지고 있다. 

- `레지스터`
- `1차 캐시(L1)`: 초고속 캐시, 각 코어 전용
- `2차 캐시(L2)`: 고속 캐시, 각 코어 전용
- `3차 캐시(L3)`: 준고속 캐시, CPU 전체가 공유

> `L`:  `Level`의 줄임말<br>`캐시`: 자주 사용하는 데이터를 고속으로 접근할 수 있는 임시 저장소



이들은 **메인 메모리보다 속도가 더 빠르지만**, 메모리에 비해 **용량이 매우 작다**. 

>  그런데 잠깐! 메모리 영역이 "따로" 존재함에도, CPU는 왜 메모리를 사용할까? 

아래 이미지를 살펴보자. 



<img src=https://images.velog.io/images/bky373/post/af956bcb-5966-4a40-8127-4413b86e0d20/image.png width=490px height=310px>

> Ref. https://www.doc.ic.ac.uk/~eedwards/compsys/memory/index.html

**1. 처리 지연 단축**

메모리를 이용하기 위해, 메모리 컨트롤러를 경유해서 CPU 밖으로 나가야 한다. 하지만 고속 CPU에서는 이런 처리 지연을 허용하지 않는다. 결국 CPU는 **처리 지연(Latency, 레이턴시)을 줄이기 위해서** 가장 **자주 사용하는 명령/데이터를 코어 가까이** 배치하는 것이다.

**2. 접근 속도 향상**

그리고 CPU 안에서 메모리 영역을 여러 개로 나누는 이유는 **접근 속도** 때문이다. 일반적으로 **캐시 메모리가 커질수록 액세스 속도가 느려진다**. 하지만 CPU 가까운 곳에 많은 캐시를 두어야 처리 속도가 빨라진다. 이 때문에 캐시를 여러 단계로 배치해서 **초고속**으로 접근하고 싶은 데이터는 **L1 캐시**에, **고속**으로 액세스하고 싶은 데이터는 **L2 캐시**에 두는 방식을 사용한다.

<img src=https://images.velog.io/images/bky373/post/590b3a29-7851-4b90-99d8-522f25d89734/image.png width=350px height=380px>

> Ref. http://tutorials.jenkov.com/java-performance/modern-hardware.html


## 5. 입출력 장치

### 하드 디스크 드라이브

> HDD, Hard Disk Drive<br>보조 기억 장치 중 하나로, 흔히 아는 `로컬 디스크(C:)`나 `새 볼륨(D:)` 등이 하드 디스크의 폴더들이다

하드 디스크는 (메모리에 비해) CPU와 멀리 떨어진 곳에 위치해 있으며, 주로 **데이터 기록 및 장기 저장**을 위해 사용된다. 디스크는 메인 메모리와 달리 **전기가 없어도 데이터가 사라지지 않는다.** 아래 그림에서는 HDD의 내부 요소들을 자세히 보여주고 있다. (금속 재질인 플래터에 데이터를 기록하기 때문에 단단하다는 뜻으로 하드라는 이름을 사용한다.)

 <img src=https://images.velog.io/images/bky373/post/0fa22e89-4b03-4bab-be6d-59f26649ac6b/image.png width=480px height=360px>

> Ref.  [DB의 DB님 블로그 - 물리 서버 내부 구조](https://dabingk.tistory.com/24)

HDD 내부에는 자기(magnetic) 원반이 여러 개 들어 있는데, 원반이 고속으로 회전하고 헤드를 사용하여 읽기/쓰기를 처리한다. 이는 CD나 DVD와 같은 구조를 가지고 있다.

> HDD 작동 영상: [How a Hard Drive works in Slow Motion - The Slow Mo Guys](https://youtu.be/3owqvmMf6No)

원반의 회전에는 물리적인 한계가 있기 때문에 순식간에 데이터에 액세스할 수는 없다. 즉, **메인 메모리에 비하면 속도가 매우 느린 편이다.** 굳이 시간을 따지면, 대개 수 밀리초에서 수십 밀리초 정도의 시간이 걸린다(메모리는 수~수십 마이크로초가 걸린다. 밀리는 10^(-3)을, 마이크로는 10^(-6)을 의미한다.)

최근에는 기술의 발달로, **SSD** (Solid State Disk, 반도체 디스크)를 많이 이용하는 추세다. SSD는 물리적인 회전을 하지 않는다. 메모리처럼 **반도체**로 만들어져 있으며, HDD처럼 **전기가 없어도 데이터가 사라지지 않는다**. 이와 같은 SSD의 등장으로, 메모리와 기억 장치 간 속도 차이가 거의 없어지고 있다.

### 네트워크 인터페이스

> Network Interface, **네트워크 접촉 지점**

네트워크 인터페이스는 서버와 외부 장비를 연결하기 위한, **외부 접속용 인터페이스**이다. <br>서버 외부 장비로는 네트워크에 연결된 다른 서버나 저장소 장치가 있다. 아래 사진은 이더넷(Ethernet)의 네트워크 어댑터이다.

> 이더넷(Ethernet): [컴퓨터 네트워크](https://ko.wikipedia.org/wiki/컴퓨터_네트워크) 기술의 하나로, 일반적으로 [LAN](https://ko.wikipedia.org/wiki/근거리_통신망), [MAN](https://ko.wikipedia.org/wiki/도시권_통신망) 및 [WAN](https://ko.wikipedia.org/wiki/광역_통신망)에서 가장 많이 활용되는 기술 규격

 <img src=https://images.velog.io/images/bky373/post/6b265723-e097-404c-b946-859490a5193b/image.png width=480px height=310px>

> Ref.  [DB의 DB님 블로그 - 물리 서버 내부 구조](https://dabingk.tistory.com/24)

## 6. 버스

> Bus, 회선

버스는 서버 내부에 있는 **컴포넌트들을 서로 연결시키는 회선** 을 가리킨다. 버스에서 중요한 것은 버스가 어느 정도의 **데이터 전송 능력(대역)** 을 가지고 있는가이다.

### 대역 

> Throughput,  스루풋,  **처리량** 

대역은 간단히 **데이터 전송 능력**을 의미한다. 대역은 아래와 같은 식으로 그 값이 결정된다.

> 한번에 데이터를 보낼 수 있는 데이터의 폭(전송폭) X 1초에 전송할 수 있는 횟수(전송 횟수)
>
> 전송 횟수는 `1초 / 1 처리당 소요 시간(응답 시간)` 으로 표현할 수 있다.

<img src=https://images.velog.io/images/bky373/post/08cab3aa-f03f-4cee-b23f-3934ff21b82f/image.png width=480px height=310px>

> Ref.  [DB의 DB님 블로그 - 물리 서버 내부 구조](https://dabingk.tistory.com/24)

### 버스 대역

버스 대역에서 기억해야 할 부분은, **CPU에 가까울수록 버스 대역이 크다**는 점이다. 다시 말해, **CPU에 가까울수록 1초당 전송량이 크다.** CPU와 메모리는 대량으로 데이터를 교환해서 매우 빠른 전송 능력(예, 12.8GB/s)이 요구되기 때문에 CPU 바로 앞에 위치한다. 반대로 USB 3.0 포트는 저속 전송 능력(예, 500MB/s)을 가지고 있기 때문에 PCH 앞에 배치해도 괜찮다. 

일상에서 접하는 대역에는 광랜 인터넷이 있다. 이는 최대 1GBps = 125MB/s 대역으로 통신이 가능하다. CPU는 20.8GB/s의 처리가 가능한 것을 보면 대역의 중요성을 알 수 있다.

---

버스 흐름에서 중요한 것은 CPU와 장치 사이에 병목 현상(Bottleneck)이 없어야 한다는 것이다. 

> 병목 현상은 데이터 전송이 어떤 이유로 막혀 있는 상태를 의미한다.

---

## 7. 정리

CPU부터 HDD, 네트워크 등의 I/O 장치까지 일련의 데이터 흐름을 살펴보았다. 아래 그림을 보면, HDD 데이터가 CPU에 이르기까지 여정이 얼마나 먼지 알 수 있다. HDD 데이터는 여러 대의 전송 버스를 지나서 몇 번이나 캐시된 후에 CPU에 이른다. 또한, CPU에 가까울수록 고속이고 멀수록 대용량인 것을 알 수 있다. 

<img src=https://images.velog.io/images/bky373/post/8e280b98-3b6b-4ab3-92d2-970e5b3d74e8/image.png width=480px height=310px>

> Ref.  [DB의 DB님 블로그 - 물리 서버 내부 구조](https://dabingk.tistory.com/24)

## Ref.

> [그림으로 공부하는 IT 인프라 구조(개정판)](http://www.yes24.com/Product/Goods/95800974)